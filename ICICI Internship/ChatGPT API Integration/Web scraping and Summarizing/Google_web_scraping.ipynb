{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b5d414f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harikishan/anaconda3/envs/Hari/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (2.0.2) or chardet (3.0.4)/charset_normalizer (2.1.1) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "import re\n",
    "from googlesearch import search  \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea89f761",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_links = []\n",
    "link_count = 1\n",
    "with open(\"old_links.txt\", \"r\") as old_links_file:\n",
    "    for line in old_links_file:\n",
    "        old_links.append(line.strip())\n",
    "        link_count += 1\n",
    "old_links_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ef03f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.eesc.europa.eu/sites/default/files/files/qe-01-19-295-en-n.pdf\n",
      "new link found\n",
      "https://www.oecd.org/competition/digital-disruption-in-banking-and-its-impact-on-competition-2020.pdf\n",
      "new link found\n",
      "https://www.bis.org/publ/bppdf/bispap117.pdf\n",
      "new link found\n",
      "https://www.imf.org/en/About/Factsheets/IMF-Lending\n",
      "new link found\n",
      "https://www.whitehouse.gov/briefing-room/statements-releases/2023/05/31/u-s-eu-joint-statement-of-the-trade-and-technology-council-2/\n",
      "new link found\n",
      "https://www.gatesfoundation.org/our-work/programs/global-growth-and-opportunity/financial-services-for-the-poor\n",
      "new link found\n",
      "https://www.worldbank.org/en/who-we-are/ibrd\n",
      "new link found\n",
      "https://www.adb.org/sites/default/files/publication/182532/adbi-wp564.pdf\n",
      "new link found\n",
      "https://www.un.org/sustainabledevelopment/wp-content/uploads/2022/03/2021-Report.pdf\n",
      "exists in old\n",
      "https://www.mckinsey.com/industries/financial-services/our-insights/global-banking-annual-review\n",
      "new link found\n",
      "https://espas.eu/files/espas_files/about/espas-report-2015.pdf\n",
      "new link found\n"
     ]
    }
   ],
   "source": [
    "query = \"Digital loans challenges and solutions to overcome in United states, European countries\"\n",
    "links = []\n",
    "for url in search(query, num_results=10, sleep_interval=2,advanced=False):\n",
    "    print(url)\n",
    "    if url not in old_links:\n",
    "        links.append(url)\n",
    "        old_links.append(url)\n",
    "        print(\"new link found\")\n",
    "    else:\n",
    "        print(\"exists in old\")\n",
    "        \n",
    "with open(\"old_links.txt\", \"w\") as old_links_file1:\n",
    "    for line in old_links:\n",
    "        old_links_file1.write(line+'\\n')\n",
    "old_links_file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8c6bec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-07 15:33:58.165179: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-07 15:33:58.383254: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-07 15:33:58.423036: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/opt/gurobi1000/linux64/lib:/opt/gurobi1000/linux64/lib\n",
      "2023-06-07 15:33:58.423055: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-06-07 15:33:59.445114: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/opt/gurobi1000/linux64/lib:/opt/gurobi1000/linux64/lib\n",
      "2023-06-07 15:33:59.445186: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/opt/gurobi1000/linux64/lib:/opt/gurobi1000/linux64/lib\n",
      "2023-06-07 15:33:59.445191: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-06-07 15:34:02.968602: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-06-07 15:34:02.968627: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (dell): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "#links\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "\n",
    "sp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "all_stopwords = sp.Defaults.stop_words\n",
    "#all_stopwords.add('<','title>','</title>','<p class=\"_21c54\">','</p>')\n",
    "all_stopwords = {'<','/title','title=','>','/','p','class=','_21c54',\n",
    "                  '/p','/a','href=','#','/sup','[',']', 'cite_ref-',\n",
    "                  'cite_note-','sup','br/','https://','id=',\"''\",'<p>',\n",
    "                  '<p class=','<p align=\"center\"','class=','<a href=','='}\n",
    "\n",
    "#url = 'https://www.imf.org/-/media/Files/Publications/WP/2021/English/wpiea2021090-print-pdf.ashx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2638618",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(columns=['Title','Content'])\n",
    "for url in links: \n",
    "    print(\"Parsing: \",url)\n",
    "    cont=\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "    title=str(soup.find('title'))\n",
    "    content = str(soup.findAll('p'))\n",
    "    text_tokens = word_tokenize(content)\n",
    "    tokens_without_sw= [word for word in text_tokens if not word in all_stopwords]\n",
    "    tle=\"\"\n",
    "    for t in tokens_without_sw:\n",
    "        tle += ' ' + t\n",
    "    #print(tle[:1000])\n",
    "    title = title[7:len(title)-8]\n",
    "    data={'Title':title,'Content':tle}\n",
    "    df= df.append(data,ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e30d2246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  (Content) % PDF-1.4 % ���� 13\n",
      "1 Financial assistance instruments | European Stability Mechanism (Content) , member__position \n",
      "2  (Content) % PDF-1.6 % ���� 40\n",
      "3  (Content) % PDF-1.6 % ���� 35\n",
      "4 You’ve Received a Message: Your Loan Has Been Approved (Content) c02v2-credit , styl\n",
      "5  (Content) % PDF-1.6 % ���� 18\n",
      "6 The IMF: The World’s Controversial Financial Firefighter | Council on Foreign Relations (Content) card-article__topic\n",
      "7 ERROR: The request could not be satisfied (Content)\n",
      "8  (Content) % PDF-1.5 % ���� 10\n",
      "9  (Content) % PDF-1.5 % ���� 1 \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(links)):\n",
    "    print(i, df['Title'].iloc[i], '(Content)' + str(df['Content'].iloc[i])[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d052f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "61286ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import openai\n",
    "\n",
    "openai.api_key = '###### USE YOUR API KEY #######'\n",
    "\n",
    "def call_chatGPT(query):\n",
    "    messages = [{\"role\": \"user\", \"content\": query}]\n",
    "    chat = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=messages)\n",
    "    reply = chat.choices[0].message.content\n",
    "    return reply\n",
    "\n",
    "def summarize_ChatGPT(texts):\n",
    "    summarized_text = \"\"\n",
    "    max_tokens = 4000\n",
    "    print(\"Input size = \",len(texts))\n",
    "    for i in range(math.ceil(len(texts)/max_tokens)):\n",
    "        text_chunk = texts[i*max_tokens:(i*max_tokens)+max_tokens]\n",
    "        print(\"{:.2f}\".format((i/math.ceil(len(texts)/max_tokens))*100),'%')\n",
    "        query = \"Summarize and list the challenges and its respective solutions to digital lending with headings: \" + text_chunk\n",
    "        summarized_text = summarized_text + '\\n***START***\\n' + call_chatGPT(query) + '\\n***END***\\n' \n",
    "        time.sleep(20)\n",
    "    print(\"Output size = \",len(summarized_text))\n",
    "    return summarized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "e540f850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.describe()['Title'].iloc[0]\n",
    "type(df['Title'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "5c042b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size =  10151\n",
      "0.00 %\n",
      "33.33 %\n",
      "66.67 %\n",
      "Output size =  2603\n",
      "Link  2\n",
      "Input size =  8524\n",
      "0.00 %\n",
      "33.33 %\n",
      "66.67 %\n",
      "Output size =  3853\n",
      "Link  3\n",
      "Input size =  403\n",
      "0.00 %\n",
      "Output size =  1701\n",
      "Link  4\n",
      "Input size =  17339\n",
      "0.00 %\n",
      "20.00 %\n",
      "40.00 %\n",
      "60.00 %\n",
      "80.00 %\n",
      "Output size =  8029\n",
      "Link  5\n",
      "Input size =  15861\n",
      "0.00 %\n",
      "25.00 %\n",
      "50.00 %\n",
      "75.00 %\n",
      "Output size =  5090\n",
      "Link  6\n",
      "Input size =  5895\n",
      "0.00 %\n",
      "50.00 %\n",
      "Output size =  1548\n",
      "Link  7\n",
      "Input size =  14524\n",
      "0.00 %\n",
      "25.00 %\n",
      "50.00 %\n",
      "75.00 %\n",
      "Output size =  5187\n",
      "Link  8\n",
      "Input size =  7871\n",
      "0.00 %\n",
      "50.00 %\n",
      "Output size =  2592\n",
      "Link  9\n",
      "Input size =  26163\n",
      "0.00 %\n",
      "14.29 %\n",
      "28.57 %\n",
      "42.86 %\n",
      "57.14 %\n",
      "71.43 %\n",
      "85.71 %\n",
      "Output size =  6827\n",
      "Link  10\n",
      "Input size =  8640\n",
      "0.00 %\n",
      "33.33 %\n",
      "66.67 %\n",
      "Output size =  5422\n",
      "Link  11\n"
     ]
    }
   ],
   "source": [
    "text_file = open(\"test.txt\", \"a\")\n",
    "for i in range(1,df['Title'].count()):\n",
    "    summary = summarize_ChatGPT(df['Content'].iloc[i])\n",
    "    print('Link ',i+1)\n",
    "    #summary = \"Hi\"\n",
    "    texts = '\\n===================================================================================================================================================================\\n'\\\n",
    "            + 'Query: ' + query + '\\n'\\\n",
    "            + str(link_count) + ' Title: ' + df['Title'].iloc[i] \\\n",
    "            + '\\nReference: ' + links[i] \\\n",
    "            + '\\nContent: \\n'+ summary \\\n",
    "            + '\\n====================================================================================================================================================================\\n\\n\\n'\n",
    "    link_count += 1\n",
    "    text_file.write(texts)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aa8e03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
